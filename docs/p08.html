<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Yoo Ri Hwang" />


<title>Portfoilio 8 : SEM</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Portfolio</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Index</a>
</li>
<li>
  <a href="p01.html">Portfolio 1</a>
</li>
<li>
  <a href="p02.html">Portfolio 2</a>
</li>
<li>
  <a href="p03.html">Portfolio 3</a>
</li>
<li>
  <a href="p04.html">Portfolio 4</a>
</li>
<li>
  <a href="p05.html">Portfolio 5</a>
</li>
<li>
  <a href="p06.html">Portfolio 6</a>
</li>
<li>
  <a href="p07.html">Portfolio 7</a>
</li>
<li>
  <a href="p08.html">Portfolio 8</a>
</li>
<li>
  <a href="p09.html">Portfolio 9</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfoilio 8 : SEM</h1>
<h4 class="author">Yoo Ri Hwang</h4>
<h4 class="date">3/28/2022</h4>

</div>


<div id="overview" class="section level2">
<h2>Overview</h2>
<p>In this project, I tried SEM. .</p>
<p>Also, I referred many materials (see the readme file).</p>
<p>portfolio 8 for ds4p</p>
<p>main theme: Structure equation modeling</p>
<p>Reference1: <a
href="https://quantdev.ssri.psu.edu/tutorials/structural-equation-modeling-r-using-lavaan"
class="uri">https://quantdev.ssri.psu.edu/tutorials/structural-equation-modeling-r-using-lavaan</a><br />
Reference2: <a href="https://stats.oarc.ucla.edu/r/seminars/rsem/"
class="uri">https://stats.oarc.ucla.edu/r/seminars/rsem/</a><br />
Reference3: <a href="https://www.ianruginski.com/post/sem_handout7/"
class="uri">https://www.ianruginski.com/post/sem_handout7/</a><br />
Reference4: <a
href="https://bookdown.org/bean_jerry/using_r_for_social_work_research/structural-equation-modeling.html"
class="uri">https://bookdown.org/bean_jerry/using_r_for_social_work_research/structural-equation-modeling.html</a><br />
Reference5: <a
href="https://www.lexjansen.com/wuss/2006/tutorials/TUT-Suhr.pdf"
class="uri">https://www.lexjansen.com/wuss/2006/tutorials/TUT-Suhr.pdf</a></p>
<div id="what-is-sem" class="section level3">
<h3>What is SEM</h3>
<p>Source: in the readme file.</p>
<p>Structure Equation Modeling (SEM) analysis the network of
relationship between the variables (including latent constructs, and
measured variable ).</p>
<p>Unlike other conventional stat techniques, SES reqiures model
specification( including measurement error specification)</p>
<p>SES is linear statistics technique, and do not provide causality
test.</p>
<p>Keep in mind that SES do not provide default model. SEM has a
powerful weapon- intuitive visulaization.</p>
<p><em>Goals</em> 1) patterns of cov/cor among the variables 2) how much
variance can be explianed by this specificed model.</p>
</div>
<div id="packages" class="section level3">
<h3>Packages</h3>
<pre class="r"><code>library(lavaan)</code></pre>
<pre><code>## Warning: package &#39;lavaan&#39; was built under R version 4.1.3</code></pre>
<pre><code>## This is lavaan 0.6-11
## lavaan is FREE software! Please report any bugs.</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v ggplot2 3.3.6     v purrr   0.3.4
## v tibble  3.1.4     v dplyr   1.0.8
## v tidyr   1.2.0     v stringr 1.4.0
## v readr   2.1.2     v forcats 0.5.1</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package &#39;readr&#39; was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 4.1.3</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(psych)</code></pre>
<pre><code>## Warning: package &#39;psych&#39; was built under R version 4.1.3</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre><code>## The following object is masked from &#39;package:lavaan&#39;:
## 
##     cor2cov</code></pre>
<pre class="r"><code>library(MASS)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>library(mvnormalTest)</code></pre>
<pre><code>## Warning: package &#39;mvnormalTest&#39; was built under R version 4.1.3</code></pre>
<pre><code>## 
## Attaching package: &#39;mvnormalTest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:psych&#39;:
## 
##     mardia</code></pre>
<pre class="r"><code>library(semPlot)</code></pre>
<pre><code>## Warning: package &#39;semPlot&#39; was built under R version 4.1.3</code></pre>
</div>
<div id="simulate-the-data" class="section level3">
<h3>Simulate the data</h3>
<pre class="r"><code>demo.model &lt;- &#39;
y ~ .5*f 

f =~ .8*x1 + .8*x2 + .8*x3 + .8*x4 + .8*x5  

x1 ~~ (1-.8^2)*x1
x2 ~~ (1-.8^2)*x2
x3 ~~ (1-.8^2)*x3
x4 ~~ (1-.8^2)*x4
x5 ~~ (1-.8^2)*x5
&#39;
simData &lt;- lavaan::simulateData(demo.model, sample.nobs=200)

# see the describtive stats
psych::describe(simData)</code></pre>
<pre><code>##    vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se
## x1    1 200  0.04 1.03   0.05    0.08 0.99 -2.97 2.81  5.79 -0.25     0.08 0.07
## x2    2 200 -0.04 1.10  -0.02   -0.02 1.14 -2.97 2.93  5.90 -0.11     0.01 0.08
## x3    3 200  0.06 1.06   0.12    0.09 0.98 -3.33 3.01  6.35 -0.28     0.51 0.07
## x4    4 200  0.02 1.10   0.08    0.02 1.23 -2.76 3.09  5.86 -0.04    -0.49 0.08
## x5    5 200  0.06 1.02   0.07    0.04 1.00 -2.66 2.53  5.19  0.11    -0.25 0.07
## y     6 200  0.00 1.08   0.02    0.02 1.18 -3.17 3.22  6.38 -0.11     0.04 0.08</code></pre>
<pre class="r"><code># multivariate nurmality test 

mv&lt;-mardia(simData)
mv</code></pre>
<pre><code>## $mv.test
##           Test Statistic p-value Result
## 1     Skewness   52.2847  0.6163    YES
## 2     Kurtosis    0.0416  0.9668    YES
## 3 MV Normality      &lt;NA&gt;    &lt;NA&gt;    YES
## 
## $uv.shapiro
##    W      p-value UV.Normality
## x1 0.9914 0.2829  Yes         
## x2 0.9944 0.6621  Yes         
## x3 0.9903 0.1956  Yes         
## x4 0.9931 0.4722  Yes         
## x5 0.9935 0.5307  Yes         
## y  0.9958 0.8552  Yes</code></pre>
<pre class="r"><code>#?simulateData

sim.cor &lt;-cor(simData, use=&quot;pairwise.complete.obs&quot;, method=&quot;pearson&quot;)
sim.cor</code></pre>
<pre><code>##           x1        x2        x3        x4        x5         y
## x1 1.0000000 0.7111977 0.7016938 0.6912733 0.6421563 0.3532336
## x2 0.7111977 1.0000000 0.7100584 0.6924437 0.6727274 0.3796734
## x3 0.7016938 0.7100584 1.0000000 0.6722241 0.7182953 0.3118240
## x4 0.6912733 0.6924437 0.6722241 1.0000000 0.6692418 0.2807331
## x5 0.6421563 0.6727274 0.7182953 0.6692418 1.0000000 0.2970388
## y  0.3532336 0.3796734 0.3118240 0.2807331 0.2970388 1.0000000</code></pre>
</div>
<div id="specify-the-model" class="section level3">
<h3>specify the model</h3>
<pre class="r"><code>tofit.model &lt;- &#39;
y ~ f 
f =~ x1+ x2 + x3 + x4 + x5 
x1 ~~ x1 
x2 ~~ x2 
x3~~x3 
x4~~x4 
x5~~x5 
&#39;

tofit.model_m &lt;- sem(tofit.model, simData)

summary(tofit.model_m, fit.measures=T)</code></pre>
<pre><code>## lavaan 0.6-11 ended normally after 22 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        12
##                                                       
##   Number of observations                           200
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 9.912
##   Degrees of freedom                                 9
##   P-value (Chi-square)                           0.358
## 
## Model Test Baseline Model:
## 
##   Test statistic                               710.250
##   Degrees of freedom                                15
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.999
##   Tucker-Lewis Index (TLI)                       0.998
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -1423.811
##   Loglikelihood unrestricted model (H1)      -1418.854
##                                                       
##   Akaike (AIC)                                2871.621
##   Bayesian (BIC)                              2911.201
##   Sample-size adjusted Bayesian (BIC)         2873.184
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.023
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.085
##   P-value RMSEA &lt;= 0.05                          0.695
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   f =~                                                
##     x1                1.000                           
##     x2                1.094    0.076   14.333    0.000
##     x3                1.050    0.073   14.335    0.000
##     x4                1.055    0.078   13.538    0.000
##     x5                0.968    0.072   13.395    0.000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   y ~                                                 
##     f                 0.498    0.090    5.559    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .x1                0.326    0.041    7.993    0.000
##    .x2                0.341    0.044    7.702    0.000
##    .x3                0.314    0.041    7.700    0.000
##    .x4                0.408    0.050    8.218    0.000
##    .x5                0.358    0.043    8.294    0.000
##    .y                 0.977    0.099    9.838    0.000
##     f                 0.723    0.103    7.042    0.000</code></pre>
<pre class="r"><code>inspect(tofit.model_m)</code></pre>
<pre><code>## $lambda
##    f y
## x1 0 0
## x2 2 0
## x3 3 0
## x4 4 0
## x5 5 0
## y  0 0
## 
## $theta
##    x1 x2 x3 x4 x5 y 
## x1  6               
## x2  0  7            
## x3  0  0  8         
## x4  0  0  0  9      
## x5  0  0  0  0 10   
## y   0  0  0  0  0  0
## 
## $psi
##   f  y 
## f 12   
## y  0 11
## 
## $beta
##   f y
## f 0 0
## y 1 0</code></pre>
<pre class="r"><code>semPlot::semPaths(tofit.model_m)</code></pre>
<p><img src="p08_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>lavaan package’s notation</p>
<p><strong>~ : predict</strong> (y~x: y is predicted by x)</p>
<p><strong>=~ : indicator</strong> (latent variable =~ observed
indicator)</p>
<p><strong>~~</strong> Covariance</p>
<p><strong>~1: intercept or mean </strong> x~1 : mean of variable x</p>
<p><strong>1</strong>* fixed parameter or loading to one</p>
<p><strong>NA</strong>* frees parameter or loading</p>
<p><strong>a</strong>*labels the parameter ‘a’ for model constraints</p>
</div>
</div>
<div id="simple-regression" class="section level2">
<h2>Simple regression</h2>
<p>before going further, let’s try simple regression</p>
<pre class="r"><code>hey&lt;-lm(y~x2, simData)
summary(hey)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x2, data = simData)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2621 -0.6406 -0.0049  0.5680  2.8203 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.01557    0.07075   0.220    0.826    
## x2           0.37167    0.06436   5.775 2.94e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9999 on 198 degrees of freedom
## Multiple R-squared:  0.1442, Adjusted R-squared:  0.1398 
## F-statistic: 33.35 on 1 and 198 DF,  p-value: 2.943e-08</code></pre>
<p>results interpretaion:</p>
<p>as one unit increase in x1, the y score improves approaximatly 0.508,
and Significant. the residual standard error is 1.087. the residual
variance is (1.087)^2 = 1.181569</p>
<p>This can be done by Lavaan packages</p>
<pre class="r"><code>hey2&lt;-&#39;
y ~ 1 + x2
x2~~x2
&#39;

hey2fit&lt;-sem(hey2,data=simData)
summary(hey2fit)</code></pre>
<pre><code>## lavaan 0.6-11 ended normally after 10 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         5
##                                                       
##   Number of observations                           200
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   y ~                                                 
##     x2                0.372    0.064    5.804    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .y                 0.016    0.070    0.221    0.825
##     x2               -0.038    0.078   -0.495    0.621
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     x2                1.207    0.121   10.000    0.000
##    .y                 0.990    0.099   10.000    0.000</code></pre>
<pre class="r"><code>semPlot::semPaths(hey2fit)</code></pre>
<p><img src="p08_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>results interpretaion:</p>
<p>the regression coifficient (0.508) is the same.</p>
<p>However, some difference is here. ML and OLS provide different
residual variance but the same coefficients.</p>
</div>
<div id="path-analysis" class="section level2">
<h2>Path analysis</h2>
<p>What is different between SEM and path analysis?</p>
<p>“SEM is a combination of multiple regression and factor analysis.
Path analysis deals only with measured variables. two or more measured
variables” (Source:<a
href="https://theicph.com/wp-content/uploads/2016/09/How-to-conduct-Path-Analysis-and-SEM-for-Health-Research_24-Sep-2016_Prof-Bhisma-Murti.pdf"
class="uri">https://theicph.com/wp-content/uploads/2016/09/How-to-conduct-Path-Analysis-and-SEM-for-Health-Research_24-Sep-2016_Prof-Bhisma-Murti.pdf</a>)
#### Data simulation</p>
<pre class="r"><code>set.seed(1234)
x&lt;-rnorm(100)
m&lt;-0.5*x + rnorm(100)
y&lt;-0.7*m + rnorm(100)
data &lt;-data.frame(x=x,m=m,y=y)</code></pre>
<div id="model-specification" class="section level4">
<h4>model specification</h4>
<pre class="r"><code>medmodel&lt;-&#39;
y~c*x
m~a*x
y~b*m
# indirect effect (a*b)
ab:=a*b
# total effect
total:=c+(a*b)
&#39;</code></pre>
<pre class="r"><code>medmodel_m&lt;-sem(medmodel, data=data)
summary(medmodel_m, fit.measures=T)</code></pre>
<pre><code>## lavaan 0.6-11 ended normally after 1 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         5
##                                                       
##   Number of observations                           100
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Model Test Baseline Model:
## 
##   Test statistic                                84.319
##   Degrees of freedom                                 3
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.000
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)               -281.061
##   Loglikelihood unrestricted model (H1)       -281.061
##                                                       
##   Akaike (AIC)                                 572.122
##   Bayesian (BIC)                               585.148
##   Sample-size adjusted Bayesian (BIC)          569.357
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.000
##   P-value RMSEA &lt;= 0.05                             NA
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   y ~                                                 
##     x          (c)    0.036    0.104    0.348    0.728
##   m ~                                                 
##     x          (a)    0.474    0.103    4.613    0.000
##   y ~                                                 
##     m          (b)    0.788    0.092    8.539    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .y                 0.898    0.127    7.071    0.000
##    .m                 1.054    0.149    7.071    0.000
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     ab                0.374    0.092    4.059    0.000
##     total             0.410    0.125    3.287    0.001</code></pre>
<pre class="r"><code>semPaths(medmodel_m)</code></pre>
<p><img src="p08_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="confirmatory-factor-analysls" class="section level2">
<h2>Confirmatory factor analysls</h2>
<p>load the data</p>
<pre class="r"><code>library(foreign)
dat &lt;- read.spss(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2018/05/SAQ.sav&quot;,
                                             to.data.frame=TRUE, use.value.labels = FALSE)</code></pre>
<pre><code>## re-encoding from UTF-8</code></pre>
<pre class="r"><code>head(dat,10)</code></pre>
<pre><code>##    q01 q02 q03 q04 q05 q06 q07 q08 q09 q10 q11 q12 q13 q14 q15 q16 q17 q18 q19
## 1    2   1   4   2   2   2   3   1   1   2   1   2   2   2   2   3   1   2   3
## 2    1   1   4   3   2   2   2   2   5   2   2   3   1   3   4   3   2   2   3
## 3    2   3   2   2   4   1   2   2   2   2   3   3   2   4   2   3   2   3   1
## 4    3   1   1   4   3   3   4   2   2   4   2   2   2   3   3   3   2   4   2
## 5    2   1   3   2   2   3   3   2   4   2   2   3   3   2   2   2   2   3   3
## 6    2   1   3   2   4   4   4   2   4   3   2   4   3   3   5   2   3   5   1
## 7    2   3   3   2   2   2   2   2   3   2   2   2   2   2   2   2   2   2   3
## 8    2   2   3   2   2   2   2   2   4   2   2   3   2   2   3   2   2   2   4
## 9    3   3   1   4   5   3   5   5   3   3   5   5   5   5   5   5   5   5   2
## 10   2   4   4   3   2   1   2   2   3   2   2   3   2   1   2   3   2   2   3
##    q20 q21 q22 q23
## 1    2   2   2   5
## 2    4   4   4   2
## 3    4   3   2   2
## 4    4   4   4   3
## 5    4   2   4   4
## 6    5   3   1   4
## 7    2   2   4   4
## 8    3   2   4   4
## 9    5   5   3   3
## 10   3   2   4   4</code></pre>
<p>8 items, with one factor</p>
<pre class="r"><code>cfa&lt;- &#39;
f =~ q01 + q02 + q03 + q04 + q05 + q06 + q07 + q08&#39;

cfa8&lt;- cfa(cfa, data=dat, std.lv=TRUE)
#std.lv=T automatically standardize the variance. 

summary(cfa8, fit.measures=T, standardized=T)</code></pre>
<pre><code>## lavaan 0.6-11 ended normally after 15 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        16
##                                                       
##   Number of observations                          2571
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                               554.191
##   Degrees of freedom                                20
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                              4164.572
##   Degrees of freedom                                28
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.871
##   Tucker-Lewis Index (TLI)                       0.819
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -26629.559
##   Loglikelihood unrestricted model (H1)     -26352.464
##                                                       
##   Akaike (AIC)                               53291.118
##   Bayesian (BIC)                             53384.751
##   Sample-size adjusted Bayesian (BIC)        53333.914
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.102
##   90 Percent confidence interval - lower         0.095
##   90 Percent confidence interval - upper         0.109
##   P-value RMSEA &lt;= 0.05                          0.000
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.055
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   f =~                                                                  
##     q01               0.485    0.017   28.942    0.000    0.485    0.586
##     q02              -0.198    0.019  -10.633    0.000   -0.198   -0.233
##     q03              -0.612    0.022  -27.989    0.000   -0.612   -0.570
##     q04               0.632    0.019   33.810    0.000    0.632    0.667
##     q05               0.554    0.020   28.259    0.000    0.554    0.574
##     q06               0.554    0.023   23.742    0.000    0.554    0.494
##     q07               0.716    0.022   32.761    0.000    0.716    0.650
##     q08               0.424    0.018   23.292    0.000    0.424    0.486
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .q01               0.450    0.015   30.734    0.000    0.450    0.656
##    .q02               0.685    0.019   35.300    0.000    0.685    0.946
##    .q03               0.780    0.025   31.157    0.000    0.780    0.675
##    .q04               0.499    0.018   27.989    0.000    0.499    0.555
##    .q05               0.623    0.020   31.040    0.000    0.623    0.670
##    .q06               0.951    0.029   32.711    0.000    0.951    0.756
##    .q07               0.702    0.024   28.678    0.000    0.702    0.578
##    .q08               0.581    0.018   32.849    0.000    0.581    0.764
##     f                 1.000                               1.000    1.000</code></pre>
<pre class="r"><code>semPaths(cfa8)</code></pre>
<p><img src="p08_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>interpretaion</p>
<pre class="r"><code>round(cor(dat[,1:8]),2)</code></pre>
<pre><code>##       q01   q02   q03   q04   q05   q06   q07   q08
## q01  1.00 -0.10 -0.34  0.44  0.40  0.22  0.31  0.33
## q02 -0.10  1.00  0.32 -0.11 -0.12 -0.07 -0.16 -0.05
## q03 -0.34  0.32  1.00 -0.38 -0.31 -0.23 -0.38 -0.26
## q04  0.44 -0.11 -0.38  1.00  0.40  0.28  0.41  0.35
## q05  0.40 -0.12 -0.31  0.40  1.00  0.26  0.34  0.27
## q06  0.22 -0.07 -0.23  0.28  0.26  1.00  0.51  0.22
## q07  0.31 -0.16 -0.38  0.41  0.34  0.51  1.00  0.30
## q08  0.33 -0.05 -0.26  0.35  0.27  0.22  0.30  1.00</code></pre>
<p>q 02, it is only -.23. If we see the corr table, also can find that
q02 is weakly associated with other questions. q03,</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
