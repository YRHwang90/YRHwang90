---
title: "Portfolio4: multilevel simulation"
author: "Yoo Ri Hwang"
date: "3/11/2022"
output: html_document
---


## Packages 

```{r}

library(lme4)
library(texreg)

```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Connected to Portfolio7 (disregard numeric order)
I aim to be familar with multilevel simulation in this project. 

However, I could not understand every function or every concept that
used in here (i.e., kernal density, the list things, and .x...).
However, I tried to get big picture 


## Source & Reference

Reference 1: https://education.illinois.edu/docs/default-source/carolyn-anderson/edpsy587/lectures/5-estimation/r_markdown_simulate174c1f2f-4e53-45a6-8e56-afb521343a79.html?Status=Master&sfvrsn=6574ad6b_3&download=true/https://education.illinois.edu/docs/default-source/carolyn-anderson/edpsy587/lectures/5-estimation/r_markdown_simulate174c1f2f-4e53-45a6-8e56-afb521343a79.html

Reference 2: https://personality-project.org/r/html/sim.multilevel.html

Reference 3: https://bookdown.org/marklhc/notes/simulating-multilevel-data.html#linear-growth-model

4: https://aosmith.rbind.io/2018/04/23/simulate-simulate-part-2/

5:https://journals.sagepub.com/doi/full/10.1177/2515245920965119

6:https://cran.r-project.org/web/packages/simglm/vignettes/tidy_simulation.html


# Simulation of Multilevel data 

## 1. Random intercept model 

We well generate the data as follows:



 $$Level1: Y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + r_{ij}$$
 
 $x_{ij}$ is level-1 predictor 
 
 $$r_{ij} \sim N(0,\sigma^2)$$
 Level 2: 
 
 $$\beta_{0j} = \gamma_{00} + \gamma_{01}z_{j} + u_{0j} $$
 
 $$\beta_{1j} = \gamma_{10}$$ 
 
 $z_{j}$ is level-2 predictor (AGE) 
 
 $$u_{0j} \sim N(0,\tau_0^2)$$ 
 
 Combined together:
 
 $$Y_{ij} = \gamma_{00} + \gamma_{01}z_{j} + u_{0j} + \gamma_{10}x_{ij} + r_{ij}$$
   
### Parameter

Sample size:

I will cet the number of clusters to be 100, and group size to be 20


```{r}

# sample size

N<-100 # number of group
nj<- 20 # cluster/group size 

# fixed effect parameter

gamma00<- 5
gamma01<- 2
gamma10<- 3

# set the variance of random coeffiencts

tau2<-2
sigma2<-4


```
 
### Prepare

```{r}


R.intercept<-matrix(,nrow=N*nj,ncol=7) 
head(R.intercept,10)

index<-1 # do not understand why doing this. 
```

### Generate data

 sampling Macro (e.g., school rather than student)and micro (student rather than school)

```{r}
#outer loop
for(macro in (1:N)){
  u0j=sqrt(tau2)*rnorm(1)
  age=50*runif(1)+20 #age range between 30-70
#iner loop
  for(micro in (1:nj)){
    xij=rnorm(1) #create level-1 predictor 
    z=rnorm(1) # create level-1 residual with sigma2=2
    rij=sqrt(sigma2)*z; 
# DV 
    yij=gamma00+gamma01*xij+gamma01*age+u0j+rij
    R.intercept[index,1:7] <-c(macro,micro,yij,age,xij,u0j,rij)
    index <- index+1 
  }
}

R.intercept<-as.data.frame(R.intercept)
names(R.intercept)<-c("macro","micro","yij","age","xij","u0j","rij")
head(R.intercept,10)
```


### fitting models 

```{r}


model1<-lmer(yij~xij+age+(1|macro),data=R.intercept,REML=FALSE)
summary(model1)
```


# Another example:

In the tutorial.. the model equation is not specified..
:(....

it is my guess, but I guess the model is.. 

$$Y_{ij}=\beta_{0j}+x_{ij}\beta_{1j}+e_{ij}$$
$$\beta_{0j}=\gamma_{0}+u_{0j}$$

$$\beta_{1j}=\gamma_{1}+u_{1j}$$
$$e_{ij} \sim N(0,\sigma^2)$$


$$\left[\begin{matrix}u_{0j}\\u_{1j}\\\end{matrix}\right]\sim MVN\left(\left[\begin{matrix}0\\0\\\end{matrix}\right],\left[\begin{matrix}\tau_{00}&\tau_{01}\\\tau_{10}&\tau_{11}\\\end{matrix}\right]\right)$$






## packages
```{r}


library(tidyverse)
library(mnormt)
library(lme4)

```

## Prepare

```{r}
set.seed(2208)

#sample size
cn <-20 # cluster number
cs <-4 # cluster size

#fixed effect 

gam <-c(0,0.5) # fix-effect, gamma 0 and gamma1 

#random effect 

G<-matrix(c(0.25,0,
            0, 0.125), nrow=2) # tau00, tau01, tau10, tau11

sigma2 <-1 # within-person variance (1 level, sigma^2)

```

## predictor matrix

```{r}
seq_len(cs)
xp<-cbind(1,seq_len(cs) -1) # why -1?
x <- xp[rep(seq_len(cs), cn), ]

```

## ID variable

```{r}

cn_id<-seq_len(cn)
pid<-rep(cn_id, each=cs)

print(pid)


```

## random componets 

```{r}

uj<-rmnorm(cn,mean=rep(0,2), varcov=G)
eij<-rnorm(cn*cs,sd=sqrt(sigma2))


```

## compute Betas, DV, and generate dataframe.


```{r}
## compute beta
betaj<-matrix(gam,nrow=cn,ncol=2,byrow=T)+uj



## Compute DV
y<-rowSums(x*betaj[pid,])+eij




## combine that into dataframe
sim_dat1<-tibble(y,time = x[,2],pid)
```


##  make function! 


```{r}

gen_data_sim <- function( cn, cs, gam, G, sigma2=1){

  xp<-cbind(1,seq_len(cs) -1) # why -1?
  x <- xp[rep(seq_len(cs), cn), ]
# id generation
  cn_id<-seq_len(cn)
  pid<-rep(cn_id, each=cs)
  
# random componets 
  uj<-rmnorm(cn,mean=rep(0,2), varcov=G)
  eij<-rnorm(cn*cs,sd=sqrt(sigma2))

## compute beta
  betaj<-matrix(gam,nrow=cn,ncol=2,byrow=T)+uj

## Compute DV
  y<-rowSums(x*betaj[pid,])+eij

## combine that into dataframe
  sim_dat1<-tibble(y,time = x[,2],pid)

## return data
  return(sim_dat1)
}
```

## using function

```{R}
gam <-c(0,0.5) 

G<-matrix(c(0.25,0,
            0, 0.01), nrow=2) # tau00, tau01, tau10, tau11

sigma2 <-1 # within-person variance (1 level, sigma^2)

sim_data2<-gen_data_sim(20,4,gam,G)
sim_big_sample<-gen_data_sim(200,50,gam,G) # generting sample that has larger samples 


```

## run the anaysis

```{r}

run<-function(df){
  lmer(y~time + (1|pid), data=df)
}

```

```{r}

run(sim_dat1)

run(sim_data2)

run(sim_big_sample)

```

### run the simulation

```{R}
set.seed(2208)

Nrep<-100 # number of replication 

cn <-20 # cluster number
cs <-4 # cluster size

#fixed effect 

gam <-c(0,0.5) # fix-effect, gamma 0 and gamma1 

#random effect 

G<-matrix(c(0.25,0,
            0, 0.125), nrow=2) # tau00, tau01, tau10, tau11

sim_result<-vector("list", length=Nrep)


```

#### For loop


```{r}

for (i in seq_len(Nrep)){
  sim_dat <- gen_data_sim(cn,cs,gam,G)
  sim_result[[i]] <- run(sim_dat)
}


#check

sim_result[[Nrep]]
```
### extract target statistics 

```{r}

# extract fixed effect

fixef(sim_result[[1]])

# standared error

sqrt(diag(vcov(sim_result[[1]])))

# confidence interval

confint(sim_result[[1]], parm="time")


```

```{r,message=FALSE}
  fixefs_time <- map(sim_result, 
                   ~ tibble(est = fixef(.x)[2], 
                            se = sqrt(diag(vcov(.x))[2]), 
                            ci = confint(.x, parm = "time")) %>% 
                transmute(est, se, li = ci[1], ui = ci[2])) %>% 
                bind_rows()

```


### summarize the results

```{r}

## YR did not learn bias yet 

#bias

summarize(fixefs_time,
          ave_est=mean(est),
          ave_se = mean(se),
          sd_est = sd(est),
          ci_coverage = mean (li <=gam[2] & ui >= gam[2])) %>%
  
  #compuate bias and SE bias 
 mutate(bias = ave_est - gam[2],
        rbias= bias/gam[2],
        se_bias = ave_se-sd_est,
        rse_bias =se_bias/sd_est,
        rmse=bias^2 + sd_est^2)

```

## exercise

sample size effects on fixed effect in this model
(not in the tutorial )
20x4 sample size (80)
```{r}


fixefs_time%>%
  ggplot(aes(x=est))+
  geom_density()
 

```
200x50 sample size 
```{r}

for (i in seq_len(Nrep)){
  sim_big_sample<-gen_data_sim(200,50,gam,G) 
  sim_result[[i]] <- run(sim_big_sample)
}


# extract fixed effect

fixef(sim_result[[1]])

# standared error

sqrt(diag(vcov(sim_result[[1]])))

# confidence interval

confint(sim_result[[1]], parm="time")

  fixefs_time <- map(sim_result, 
                   ~ tibble(est = fixef(.x)[2], 
                            se = sqrt(diag(vcov(.x))[2]), 
                            ci = confint(.x, parm = "time")) %>% 
                transmute(est, se, li = ci[1], ui = ci[2])) %>% 
                bind_rows()
  
summarize(fixefs_time,
          ave_est=mean(est),
          ave_se = mean(se),
          sd_est = sd(est),
          ci_coverage = mean (li <=gam[2] & ui >= gam[2])) %>%
  
  #compuate bias and SE bias 
 mutate(bias = ave_est - gam[2],
        rbias= bias/gam[2],
        se_bias = ave_se-sd_est,
        rse_bias =se_bias/sd_est,
        rmse=bias^2 + sd_est^2)


fixefs_time%>%
  ggplot(aes(x=est))+
  geom_density()
 
```

As this simulation graph shows, large sample size make graph more normal-like shape. 